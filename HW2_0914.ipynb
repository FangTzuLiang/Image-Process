{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMky2z7y5oeHv9zh+jGVAhf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FangTzuLiang/Image-Process/blob/main/HW2_0914.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRAD-CAM（Gradient-weighted Class Activation Mapping）:一種用於解釋CNN模型預測的視覺解釋技術"
      ],
      "metadata": {
        "id": "YoUvUG3d-xZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sn2UtNcnpdk",
        "outputId": "9e1418d3-b488-4929-da85-ddff9f29d7be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 25s 52ms/step - loss: 2.2322 - accuracy: 0.1823 - val_loss: 2.1217 - val_accuracy: 0.2637\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 2.0025 - accuracy: 0.3015 - val_loss: 1.8951 - val_accuracy: 0.3380\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 1.8307 - accuracy: 0.3540 - val_loss: 1.7623 - val_accuracy: 0.3748\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 1.7257 - accuracy: 0.3829 - val_loss: 1.6762 - val_accuracy: 0.4014\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 1.6543 - accuracy: 0.4045 - val_loss: 1.6142 - val_accuracy: 0.4173\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 1.6019 - accuracy: 0.4213 - val_loss: 1.5653 - val_accuracy: 0.4382\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 1.5618 - accuracy: 0.4335 - val_loss: 1.5264 - val_accuracy: 0.4464\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 1.5301 - accuracy: 0.4417 - val_loss: 1.4956 - val_accuracy: 0.4607\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 1.5045 - accuracy: 0.4480 - val_loss: 1.4732 - val_accuracy: 0.4624\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 1.4837 - accuracy: 0.4537 - val_loss: 1.4537 - val_accuracy: 0.4646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78c751518e20>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 用keras建立model\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# 彩色影像reshape\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "# to_categorical將目標變量進行One-Hot編碼，將類別轉為二進制\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Create a simple CNN model\n",
        "model = Sequential()# 創建一個 Sequential 模型，用於堆疊神經網路層\n",
        "# 添加一個2D卷積層，使用32個濾波器，每個濾波器大小為3x3，啟動函數為ReLU，輸入形狀為28x28x1\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 添加一個2D最大池化層，池化窗口大小為2x2\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# 添加一個全局平均池化層，用於降低Feature Map維度。降維方法:Max Pooling、Autoencoder、Feature Selection...\n",
        "model.add(GlobalAveragePooling2D())\n",
        "# 添加一個全連接層，輸出維度為10，啟動函數為softmax\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# 編譯模型\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (you can adjust epochs and batch size as needed)\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Grad-CAM function\n",
        "def grad_cam(input_model, image):\n",
        "    # 將輸入圖像擴展為4D張量，加到批次中，讓模型可以跑得更有效率\n",
        "    x = np.expand_dims(image, axis=0)\n",
        "    preds = input_model.predict(x)# 預測\n",
        "\n",
        "    # Get the last convolutional layer\n",
        "    last_conv_layer = input_model.get_layer('conv2d')\n",
        "    # 創建一個新的模型last_conv_layer_model，只包括最後一個卷積層的輸出\n",
        "    last_conv_layer_model = tf.keras.Model(input_model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # 創建一個分類器模型，用於後續計算梯度\n",
        "    # 創建一個新的輸入層y，形狀與最後一個卷積層的輸出形狀相同\n",
        "    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    y = classifier_input\n",
        "    # 將input_model的層添加到了y中\n",
        "    for layer_name in [\"global_average_pooling2d\", \"dense\"]:\n",
        "        y = model.get_layer(layer_name)(y)\n",
        "\n",
        "    # 創建一個新的模型classifier_model，輸入為classifier_input，輸出為y\n",
        "    # classifier_model是一個包含了原始model中指定的層的模型，用於進行分類操作\n",
        "    # 這個新模型將被用於後續計算梯度和生成GRAD-CAM熱度圖\n",
        "    classifier_model = tf.keras.Model(classifier_input, y)\n",
        "\n",
        "    # 使用梯度帶（GradientTape）計算梯度\n",
        "    with tf.GradientTape() as tape:\n",
        "      inputs = image[np.newaxis, ...]\n",
        "      last_conv_layer_output = last_conv_layer_model(inputs)\n",
        "\n",
        "      # 設置梯度帶以監控最後卷積層的輸出\n",
        "      tape.watch(last_conv_layer_output)\n",
        "\n",
        "      # 使用分類器模型進行預測\n",
        "      preds = classifier_model(last_conv_layer_output)\n",
        "      # 獲取預測中的最高概率類別索引\n",
        "      top_pred_index = tf.argmax(preds[0])\n",
        "      # 獲取預測中的最高概率類別的分數\n",
        "      top_class_channel = preds[:, top_pred_index]\n",
        "      print(top_pred_index)\n",
        "\n",
        "    # 計算相對於最後卷積層輸出的梯度\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # 將梯度平均以獲得池化後的梯度\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "\n",
        "    # 轉為NumPy陣列\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "\n",
        "    # 這個迴圈將對每個filters的相應區域進行梯度加權\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        # 乘以每個filters的池化梯度\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # Average over all the filters to get a single 2D array\n",
        "    gradcam = np.mean(last_conv_layer_output, axis=-1)\n",
        "    # Clip the values (equivalent to applying ReLU) and then normalise the values\n",
        "    gradcam = np.clip(gradcam, 0, np.max(gradcam)) / np.max(gradcam)\n",
        "    # 調整大小以匹配原始圖像大小\n",
        "    gradcam = cv2.resize(gradcam, (28, 28))\n",
        "    return gradcam"
      ],
      "metadata": {
        "id": "DLdGHk6opZHc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "grad_cam = grad_cam(model, X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AudytAIxplx5",
        "outputId": "77ce0fb4-68a0-4663-d734-18ffc1cc4b5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 32)                0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 650 (2.54 KB)\n",
            "Trainable params: 650 (2.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[0].squeeze(), cmap='gray')\n",
        "print(X_test[0].shape)\n",
        "plt.imshow(grad_cam, alpha=0.5, cmap='jet')"
      ],
      "metadata": {
        "id": "T1OOjkLutPjO",
        "outputId": "8246ce12-f166-4aae-d599-42859d164c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78c73d4cfac0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}